# 周报  

LWGAnet论文的复现

<img width="384" height="83" alt="eb04117426def5b5f334cd774fe79873" src="https://github.com/user-attachments/assets/24dc5fa3-927d-4252-95e9-be239ec0d533" />

这个是LWGAnetL0 的训练结果

其余的目前还在训练



<img width="215" height="213" alt="image" src="https://github.com/user-attachments/assets/95ba2217-2a00-4739-b9aa-7948fe7e0195" />
<img width="217" height="226" alt="image" src="https://github.com/user-attachments/assets/f44c3378-7f93-4b19-88ae-35efc5b94c83" />
<img width="213" height="232" alt="image" src="https://github.com/user-attachments/assets/c9c42ff2-f621-44c3-aa66-e72d912c13f2" />





<img width="843" height="307" alt="504249625-8d336766-9371-4088-a455-ec9115b4554c" src="https://github.com/user-attachments/assets/4ea017fb-4ca6-4b16-bc16-89c26cd2c45e" />


  将模型中的convnet网络替换成LWGAnet

  并做了以下适配型的改动

  <img width="1577" height="496" alt="513326797-37d815af-e26d-47e4-8eb2-0cf6a50d287c" src="https://github.com/user-attachments/assets/52afe4d5-7953-4bc6-a3a2-d2d280645f5c" />

  
<img width="1116" height="414" alt="微信图片_20251121113307_271_9" src="https://github.com/user-attachments/assets/9da8f478-1a73-4ec6-9ec6-282eefdd720c" />



改动后的结果


<img width="499" height="112" alt="4fed81e3b340313c84d28f9cb1117e3d" src="https://github.com/user-attachments/assets/4d8dd769-36f8-464c-a0ea-a0c6d46420b5" />


<img width="800" height="200" alt="9a9ca571d3f7588f88e3fa7ca62e8c00" src="https://github.com/user-attachments/assets/5d20bead-cfc1-4888-8913-323b03dba992" />


关于模型性能下降的分析

ConvNet 通过 “卷积 + 池化” 逐级学习局部→中层→高层特征，感受野随网络加深逐步扩大，适配小样本分类对 “局部判别特征” 的依赖；

LWGA 将特征划分为 GPA（微小）、RLA（局部）、SMA（中程）、SGA（全局）四分支，直接输出多尺度融合特征，


注意力模块样本依赖冲突：LWGA 的四分支注意力需大量样本学习 “局部 - 全局” 尺度分配规则（如 SGA 的长程依赖需多样本统计）

而小样本任务中每类仅 1-10 个标记样本，样本多样性不足导致 LWGA 无法学习合理注意力权重，例如 SMA 无法精准建模中尺度目标上下文，GPA 无法聚焦微小目标关键点。

