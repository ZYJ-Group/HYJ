# 周报  
##REMI：基于鲁棒嵌入和流形推理的小样本ISAR目标分类

  1.主要思路;提出了一种名为 REMI 的两阶段网络，有效解决了 ISAR 目标分类中未知图像变形和少样本问题，通过鲁棒嵌入与流形推理提升了分类性能与场景适应性。
    
  核心问题：
  
（1）未知图像变形：雷达视线、带宽、目标姿态等变化会导致 ISAR 图像拉伸、压缩、旋转或偏移，破坏目标结构信息，阻碍特征提取。
    现存方法发缺陷：变形调整方面，数据增强易引入无关信息，传统 STN（空间变换网络）可能产生无物理意义的剪切变换，且丢弃原始图像导致信息丢失。

（2）少样本问题：高质量 ISAR 图像获取受观测条件限制，部分类别标记样本稀缺，难以构建完整训练集，传统模型泛化能力不足。
    现存方法发缺陷：少样本分类方面，基于图的方法（如 GAT）易因全连接结构导致过平滑，且未考虑支持样本质量差异对推理的影响。

    
  2.方法创新与理论模型
  
REMI 网络核心设计（两阶段架构）

<img width="1369" height="542" alt="image" src="https://github.com/user-attachments/assets/142b53e7-8508-466f-826c-50cc21f125ed" />

   (1) 鲁棒嵌入阶段：解决图像变形与特征融合
   
该阶段包含MH-STN（多头空间变换网络） 和GEN（分组嵌入网络） 两个核心模块，从数据和特征层面提升鲁棒性。

MH-STN：多视角变形调整

核心改进：将传统 STN 的 6 维仿射参数降至 5 维，消除无物理意义的剪切变换；通过 tanh 函数将参数约束在 (-1,1)，结合偏移矩阵限制，避免目标结构破坏。

多头部策略：设置 3 个独立 “头部” 生成不同仿射矩阵，对输入图像进行 3 次变形调整，最终保留原始图像与所有调整图像，多视角利用结构信息。

与传统数据增强的区别：参数由网络根据图像特征自适应生成（非人工设定），且在训练和测试阶段均启用，保证结构一致性。

<img width="677" height="306" alt="image" src="https://github.com/user-attachments/assets/fceab4f5-8313-4b03-a352-1c745feb0995" />


GEN：分组特征融合与嵌入

输入处理：将原始图像与 MH-STN 生成的调整图像沿通道维度拼接，形成新的输入特征图。

分组卷积：采用 2 层分组卷积（GConv），各组独立运算减少早期特征干扰，同时加入空洞卷积扩大感受野，增强语义信息提取。

特征融合：通过空间注意力（调制可变形卷积 MDC）和通道注意力，实现中间层特征融合，平衡灵活性与计算成本；最终通过全连接层输出低维嵌入向量和方差向量，分别代表样本中心与置信区间。

<img width="1293" height="725" alt="image" src="https://github.com/user-attachments/assets/71007f6a-0937-4f3c-ae07-9b866d61224b" />


   (2) 流形推理阶段：优化样本关联与分类
   
该阶段通过MG-GAT（掩码高斯图注意力网络） 建模嵌入空间中的样本流形，解决传统图模型过平滑和节点特征表示不足的问题。

高斯节点建模：将每个样本表示为以zi为均值、为si方差的高斯分布，定义置信区间，降低低质量支持样本对推理的干扰。

掩码注意力机制：掩码注意力机制：计算节点间注意力系数后，仅保留前k个高关联邻居

多头注意力与特征更新：通过多组独立注意力头生成特征，拼接后经全连接层压缩，迭代更新节点特征；保留第一个注意力头的自注意力，融合样本自身信息，进一步提升分类准确性。

<img width="1295" height="681" alt="image" src="https://github.com/user-attachments/assets/e8ffabee-3489-4918-a8c8-a5970572f32b" />

3.实验
 核心结果

   <img width="1299" height="334" alt="image" src="https://github.com/user-attachments/assets/bb34c265-cf7b-44f4-8708-44e1af3ee5ca" />


   <img width="1322" height="663" alt="image" src="https://github.com/user-attachments/assets/a353e65a-fe34-4c54-bad7-a2a90fa3b059" />

   <img width="1357" height="302" alt="image" src="https://github.com/user-attachments/assets/795e2c41-db3f-450d-b611-13457f620e00" />


分类性能：在卫星数据集 4 种场景中，REMI 在 3-way 1-shot 场景下准确率为 66.99%-69.07%，3-way 5-shot 场景下为 74.92%-77.42%，均优于所有基线模型，尤其在场景 IV（azimuth 角和带宽 - 积累角均不同）中，较最佳基线（TPN）提升 4.02%（1-shot）和 4.08%（5-shot）。



<img width="1298" height="699" alt="image" src="https://github.com/user-attachments/assets/77dccf10-2310-4194-aac7-c395dd43b17e" />

<img width="1294" height="407" alt="image" src="https://github.com/user-attachments/assets/dfc91023-d899-4ab3-8185-5011089d38fb" />


可视化验证：MH-STN 调整后的图像能保留目标结构，而传统 STN 易导致结构破坏；MG-GAT 的稀疏注意力连接可清晰收敛到真实类别，避免传统 GAT 的密集连接过平滑问题。

4.主要贡献

  提出 MH-STN，通过参数约束和多头部策略，实现物理意义明确的多视角变形调整，保留原始图像信息，提升特征提取鲁棒性。
  
  设计 GEN，通过分组卷积和注意力融合，平衡多图像特征的互补性与计算效率，为准确推理提供高质量低维嵌入。
  
  构建 MG-GAT，结合高斯分布节点建模和掩码注意力，解决图模型过平滑和低质量样本干扰问题，优化少样本场景下的分类推理。

 5.实现目标分类算法：

 ```cpp

# 
import cv2
import numpy as np
from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler
 
# 加载训练数据
positive_samples = []
negative_samples = []
 
# 正样本和负样本的路径列表
positive_images_paths = ['path/to/positive/images/*.jpg']
negative_images_paths = ['path/to/negative/images/*.jpg']
 
for img_path in positive_images_paths:
    image = cv2.imread(img_path, 0)
    positive_samples.append(image.flatten())
 
for img_path in negative_images_paths:
    image = cv2.imread(img_path, 0)
    negative_samples.append(image.flatten())
 
# 合并样本并分割成训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(np.concatenate([positive_samples, negative_samples]), [1]*len(positive_samples) + [0]*len(negative_samples), test_size=0.2, random_state=42)
 
# 特征缩放
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)
 
# 创建SVC分类器实例
svc = SVC(kernel='linear', C=1.0)
 
# 训练分类器
svc.fit(X_train, y_train)
 
# 测试分类器
predictions = svc.predict(X_test)
accuracy = accuracy_score(y_test, predictions)
print(f"Accuracy: {accuracy}")
 
# 应用分类器到新图像
def classify_image(image_path):
    image = cv2.imread(image_path, 0)
    flattened_image = image.flatten()
    scaled_image = scaler.transform([flattened_image])
    prediction = svc.predict(scaled_image)
    return prediction
 
# 测试新图像
new_image_path = 'path/to/new/image.jpg'
result = classify_image(new_image_path)
if result == 1:
    print(f"{new_image_path} is a flame.")
else:
    print(f"{new_image_path} is not a flame.")
```
首先加载了正样本和负样本，然后将它们合并并划分为训练集和测试集。之后，我们使用标准缩放器对数据进行标准化，并创建了一个线性SVM分类器实例。接着，我们训练分类器，并在测试集上评估其性能。最后，我们定义了一个函数来对新图像进行分类，并测试这个函数。


