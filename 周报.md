# 周报  
##基于关键点提取网络的ISAR图像序列空间目标姿态估计

  1.主要思路：从逆合成孔径雷达（ISAR）图像序列中估计空间目标的姿态是一项重要但困难的任务，这源于目标复杂的电磁散射特性。
为实现自主姿态估计，本文提出一种基于关键点特征提取网络（KPEN）的新方法。通过建立目标姿态参数与关键点特征的几何关系，利用KPEN从ISAR图像中提取关键点特征，并通过非线性优化求解目标姿态及其部件尺寸。
    
  2.核心问题：
电磁散射复杂性：空间目标的ISAR图像受复杂散射特性影响，特征提取困难。
非合作性：无法预先获取目标的3D模型或安装辅助标识（如角反射器）。
    
  3.方法创新与理论模型
(1)几何投影模型：建立空间目标3D姿态（方位角α、俯仰角β）与ISAR图像2D投影的数学关系

<img width="673" height="284" alt="image" src="https://github.com/user-attachments/assets/c6ab6cb4-51d3-415a-aaf0-12e7f214203c" />

图1:空间目标姿态与ISAR成像的几何关系模型


<img width="617" height="340" alt="image" src="https://github.com/user-attachments/assets/8ff7d844-0df3-4558-bee9-ecc53cf77fc3" />

图2：3D模型与关键点分布


(2)kPEN网络设计

  主干网络：采用ResNet提取ISAR图像特征。
  输出层：预测关键点坐标及置信度
  损失函数：融合关键点存在性分类损失、中间监督损失与坐标回归损失。
  
  <img width="827" height="203" alt="image" src="https://github.com/user-attachments/assets/d5be2e4f-b5f7-4513-95ca-1c056c1849b8" />
  
图3：KPEN网络架构

(3)自主优化策略

  置信度优先筛选：选择置信度>0.9的关键点对，确保线性结构方向估计的鲁棒性。

  非线性优化求解：构建代价函数，通过粒子群算法（PSO）求解最优联合多帧ISAR图像，利用观测角度多样性提升估计精度

  实验：

  
  <img width="692" height="306" alt="image" src="https://github.com/user-attachments/assets/9abde1c3-5a53-4a52-9acc-b475c40bbd12" />
  
  <img width="693" height="236" alt="image" src="https://github.com/user-attachments/assets/b42b31c2-d0b2-49bc-a9f0-44771950bb53" />
  
  
  在12张ISAR图像中，长边投影角的估计误差相对较小，说明本文方法在关键点估计上具有较高的可信度和精度。同时，所提方法在精度上可以达到与人工筛选过程相同的数量级。
  
  <img width="693" height="265" alt="image" src="https://github.com/user-attachments/assets/b51f35a3-9d07-48bc-923e-cddb773fd970" />
  
  <img width="693" height="282" alt="image" src="https://github.com/user-attachments/assets/6660b8d2-22e7-4072-abdc-81e7f3f1296b" />

  线性结构方位的估计误差在2°以内，太阳能电池板尺寸的估计误差小于0.1 m，座舱尺寸的估计误差在0.25 m以内。

  4.结论：

1.KPEN与人工方法精度量级相当，证明自动化可行性。
2.最大误差2°对应低信噪比图像，自动化节省人力成本，适合大规模空间目标监测。

引入KPEN算法，从ISAR图像中自动提取目标线性结构向量。实验证明了该方法在关键点提取、姿态确定和分量大小估计等方面的有效性。该建议既不需要完整的目标观测数据库，也不需要在线性结构方向估计中进行人工筛选。


 5.代码实现：

<img width="400" height="1000" alt="image" src="https://github.com/user-attachments/assets/608e168f-9e3f-4b18-ab8f-f681c4fa089d" />



 数据集加载

 ```cpp

# 图像预处理
tf = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ImageNet标准化
])

class SatelliteDataset(Dataset):
    def __init__(self, annotation_file, image_size=256):
        """
        卫星关键点数据集
        
        Args:
            annotation_file: 标注文件路径
            image_size: 图像大小
        """
        self.image_size = image_size
        self.dataset = []
        
        with open(annotation_file, 'r') as f:
            for line in f:
                line = line.strip()
                if line:
                    parts = line.split()
                    if len(parts) >= 21:  # 图像路径 + 10个点 * 2坐标 = 21个元素
                        self.dataset.append(parts)
    
    def __len__(self):
        return len(self.dataset)
    
    def __getitem__(self, index):
        data = self.dataset[index]
        img_path = data[0]
        
        # 加载图像
        img_data = Image.open(img_path).convert('RGB')
        
        # 提取10个关键点坐标 (x1, y1, x2, y2, ..., x10, y10)
        points = [float(coord) for coord in data[1:21]]
        
        # 归一化到 [0, 1] 范围
        normalized_points = [coord / self.image_size for coord in points]
        
        return tf(img_data), torch.Tensor(normalized_points)

if __name__ == '__main__':
    # 测试数据集
    dataset = SatelliteDataset('data_center.txt')
    print(f"数据集大小: {len(dataset)}")
    
    for i in range(min(3, len(dataset))):
        img, points = dataset[i]
        print(f"图像形状: {img.shape}")
        print(f"关键点形状: {points.shape}")
        print(f"关键点值: {points}")
```

网络结构

 ```cpp

class SatelliteNet(nn.Module):
    def __init__(self, num_points=10, pretrained=True):
        """
        卫星关键点检测网络
        
        Args:
            num_points: 关键点数量 (10个点)
            pretrained: 是否使用预训练权重
        """
        super(SatelliteNet, self).__init__()
        
        # 使用ResNet作为backbone
        self.backbone = models.resnet50(pretrained=pretrained)
        
        # 移除原始分类头
        in_features = self.backbone.fc.in_features
        self.backbone.fc = nn.Identity()
        
        # 关键点回归头 - 输出20个值 (10个点 * 2坐标)
        self.regressor = nn.Sequential(
            nn.Linear(in_features, 1024),
            nn.ReLU(inplace=True),
            nn.Dropout(0.3),
            nn.Linear(1024, 512),
            nn.ReLU(inplace=True),
            nn.Dropout(0.3),
            nn.Linear(512, num_points * 2)  # 输出20个值
        )
    
    def forward(self, x):
        features = self.backbone(x)
        points = self.regressor(features)
        return points

if __name__ == '__main__':
    # 测试网络
    net = SatelliteNet(num_points=10)
    x = torch.randn(2, 3, 256, 256)  # 批量大小2, 3通道, 256x256图像
    output = net(x)
    print(f"输入形状: {x.shape}")
    print(f"输出形状: {output.shape}")  # 应该是 torch.Size([2, 20])
 ```

训练脚本
 
 ```cpp

def train_satellite_model():
    # 设备设置
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"使用设备: {device}")
    
    # 创建保存目录
    Path('params').mkdir(exist_ok=True)
    
    # 初始化网络
    net = SatelliteNet(num_points=10, pretrained=True).to(device)
    
    # 加载预训练权重（如果有）
    weights_path = 'params/satellite_net.pth'
    start_epoch = 1
    if os.path.exists(weights_path):
        net.load_state_dict(torch.load(weights_path, map_location=device))
        print('成功加载预训练权重')
    
    # 数据集
    dataset = SatelliteDataset('data_center.txt')
    
    # 划分训练集和验证集
    train_size = int(0.8 * len(dataset))
    val_size = len(dataset) - train_size
    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
    
    # 数据加载器
    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=2)
    val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=2)
    
    # 优化器和损失函数
    optimizer = optim.Adam(net.parameters(), lr=0.001, weight_decay=1e-5)
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, factor=0.5)
    criterion = nn.MSELoss()  # 均方误差损失
    
    # 训练参数
    num_epochs = 200
    best_val_loss = float('inf')
    patience = 15
    
    print(f"开始训练，总共 {len(dataset)} 个样本")
    print(f"训练集: {len(train_dataset)}, 验证集: {len(val_dataset)}")
    
    for epoch in range(start_epoch, num_epochs + 1):
        # 训练阶段
        net.train()
        train_loss = 0.0
        start_time = time.time()
        
        for batch_idx, (images, labels) in enumerate(train_loader):
            images, labels = images.to(device), labels.to(device)
            
            optimizer.zero_grad()
            outputs = net(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            
            train_loss += loss.item()
            
            if batch_idx % 10 == 0:
                print(f'Epoch: {epoch}/{num_epochs} | '
                      f'Batch: {batch_idx}/{len(train_loader)} | '
                      f'Loss: {loss.item():.6f}')
        
        # 验证阶段
        net.eval()
        val_loss = 0.0
        with torch.no_grad():
            for images, labels in val_loader:
                images, labels = images.to(device), labels.to(device)
                outputs = net(images)
                val_loss += criterion(outputs, labels).item()
        
        # 计算平均损失
        avg_train_loss = train_loss / len(train_loader)
        avg_val_loss = val_loss / len(val_loader)
        
        # 学习率调整
        scheduler.step(avg_val_loss)
        current_lr = optimizer.param_groups[0]['lr']
        
        print(f'Epoch: {epoch:03d} | '
              f'Train Loss: {avg_train_loss:.6f} | '
              f'Val Loss: {avg_val_loss:.6f} | '
              f'LR: {current_lr:.2e} | '
              f'Time: {time.time() - start_time:.2f}s')
        
        # 保存最佳模型
        if avg_val_loss < best_val_loss:
            best_val_loss = avg_val_loss
            torch.save(net.state_dict(), 'params/satellite_net_best.pth')
            print(f'保存最佳模型，验证损失: {avg_val_loss:.6f}')
        
        # 每10个epoch保存一次
        if epoch % 10 == 0:
            torch.save(net.state_dict(), f'params/satellite_net_epoch_{epoch}.pth')
    
    print('训练完成!')

if __name__ == '__main__':
    train_satellite_model()
```

关键点预测

 ```cpp

****def train_satellite_model():
    # 设备设置
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"使用设备: {device}")
    
    # 创建保存目录
    Path('params').mkdir(exist_ok=True)
    
    # 初始化网络
    net = SatelliteNet(num_points=10, pretrained=True).to(device)
    
    # 加载预训练权重（如果有）
    weights_path = 'params/satellite_net.pth'
    start_epoch = 1
    if os.path.exists(weights_path):
        net.load_state_dict(torch.load(weights_path, map_location=device))
        print('成功加载预训练权重')
    
    # 数据集
    dataset = SatelliteDataset('data_center.txt')
    
    # 划分训练集和验证集
    train_size = int(0.8 * len(dataset))
    val_size = len(dataset) - train_size
    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
    
    # 数据加载器
    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=2)
    val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=2)
    
    # 优化器和损失函数
    optimizer = optim.Adam(net.parameters(), lr=0.001, weight_decay=1e-5)
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, factor=0.5)
    criterion = nn.MSELoss()  # 均方误差损失
    
    # 训练参数
    num_epochs = 200
    best_val_loss = float('inf')
    patience = 15
    
    print(f"开始训练，总共 {len(dataset)} 个样本")
    print(f"训练集: {len(train_dataset)}, 验证集: {len(val_dataset)}")
    
    for epoch in range(start_epoch, num_epochs + 1):
        # 训练阶段
        net.train()
        train_loss = 0.0
        start_time = time.time()
        
        for batch_idx, (images, labels) in enumerate(train_loader):
            images, labels = images.to(device), labels.to(device)
            
            optimizer.zero_grad()
            outputs = net(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            
            train_loss += loss.item()
            
            if batch_idx % 10 == 0:
                print(f'Epoch: {epoch}/{num_epochs} | '
                      f'Batch: {batch_idx}/{len(train_loader)} | '
                      f'Loss: {loss.item():.6f}')
        
        # 验证阶段
        net.eval()
        val_loss = 0.0
        with torch.no_grad():
            for images, labels in val_loader:
                images, labels = images.to(device), labels.to(device)
                outputs = net(images)
                val_loss += criterion(outputs, labels).item()
        
        # 计算平均损失
        avg_train_loss = train_loss / len(train_loader)
        avg_val_loss = val_loss / len(val_loader)
        
        # 学习率调整
        scheduler.step(avg_val_loss)
        current_lr = optimizer.param_groups[0]['lr']
        
        print(f'Epoch: {epoch:03d} | '
              f'Train Loss: {avg_train_loss:.6f} | '
              f'Val Loss: {avg_val_loss:.6f} | '
              f'LR: {current_lr:.2e} | '
              f'Time: {time.time() - start_time:.2f}s')
        
        # 保存最佳模型
        if avg_val_loss < best_val_loss:
            best_val_loss = avg_val_loss
            torch.save(net.state_dict(), 'params/satellite_net_best.pth')
            print(f'保存最佳模型，验证损失: {avg_val_loss:.6f}')
        
        # 每10个epoch保存一次
        if epoch % 10 == 0:
            torch.save(net.state_dict(), f'params/satellite_net_epoch_{epoch}.pth')
    
    print('训练完成!')

if __name__ == '__main__':
    train_satellite_model()****
```


