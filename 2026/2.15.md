
# 周报  

##From Coarse to Fine: ISAR Object View Interpolation via Flow Estimation and GAN
##


一、
    
  核心问题：
  论文针对 ISAR 图像数据集样本量不足、分布不均衡导致的自动目标识别（ATR）精度低的问题，提出了一种结合光流估计与生成对抗网络（GAN）的粗精两阶段 ISAR 目标视角插值框架C2FIPNet，实现多方位角 ISAR 图像的插值生成与数据集扩充
    
 二、方法创新

<img width="1154" height="401" alt="image" src="https://github.com/user-attachments/assets/0fe454c8-87ee-4a3e-a814-f1135cff8dcb" />

  
核心模型：C2FIPNet 框架

提出粗精两阶段的 ISAR 目标视角插值模型，以一对不同方位角的 ISAR 图像为输入，生成中间方位角的高保真 ISAR 图像，解决光流估计插值的失真问题，整体架构分为三部分：

粗粒度插值：光流估计（RIFE 网络）

采用实时中间流估计网络 RIFE 提取两帧 ISAR 图像的双向光流场，预测中间方位角的粗插值图像，确定散射点的位置和强度，实现方位角的连续插值。
但该阶段无法精准捕捉散射点强度突变和旁瓣细节，易产生局部失真。


细粒度补全：改进 GAN

生成器采用改进 U-Net 架构：编码器用步长卷积下采样（替换最大池化），解码器用转置卷积上采样，结合跳跃连接融合高低维特征，输出高保真细插值图像；
判别器为卷积分类器，通过五组下采样模块 + SoftMax 层区分真实图像与生成图像，与生成器形成对抗训练。


多组件损失函数设计全局 - 局部 + SSIM的复合损失函数，重点优化强散射点区域，解决 ISAR 图像稀疏性导致的梯度消失问题，总损失为：

<img width="524" height="50" alt="image" src="https://github.com/user-attachments/assets/d14ac91c-2331-4da3-acb9-22c41757b36b" />

​
LGAN​：对抗损失，保证生成图像的整体真实性；

LGlobal​：全局 L1 损失，约束像素级相似度；

LLocal​：局部 L1 损失，通过 3dB 带宽准则提取强散射点区域，单独优化该区域的特征；

LSSIM​：结构相似性损失，缓解散射点旁瓣的模糊和失真，更贴合人眼视觉感知。


三、模型结构


1.LWGANet整体架构LWGANet的架构分为四个阶段，通过逐步降低特征维度（1/4、1/8、1/16、1/32）实现多尺度特征提取。每个阶段包含LWGA模块和下采样过程，其中下采样采用DRFD模块以保留细节特征


<img width="1577" height="496" alt="image" src="https://github.com/user-attachments/assets/37d815af-e26d-47e4-8eb2-0cf6a50d287c" />




 2.LWGA模块

LWGA用于有效提取多尺度对象的特征。它将输入特征图分割成四个等分的子段，每个子段通过特定的注意力模块进行处理，最后把四个结果拼接后输出：
    
   1. 门点注意力（GPA）模块：
   
   基于点注意力机制，优先提取小尺寸对象的特征，保留细微差异。GPA模块通过卷积操作扩展和恢复特征图的通道，并利用GELU激活函数与Sigmoid操作生成注意力图，最终将输入特征与注意力图加权相加，得到增强后的输出特征。
    
  2. 规则局部注意力（RLA）模块：
  
  基于标准卷积操作，提取局部特征。如图3所示的RLA模块处理特征X₂，类似于标准卷积。X₂经过卷积操作生成X₂'。随后，通过批量归一化和激活函数处理，得到输出特征R₂。
    
   3. 稀疏中程注意力（SMA）模块：
   
   结合上下文信息，提取中等尺度对象的特征，特别是具有不规则结构的对象。如图3所示的SMA模块以特征X₃为输入。首先，用TGFI模块将其特征尺寸缩小至X₃'，从而在扩大感受野的同时保留原始位置坐标Lp。随后，SMA处理X₃'生成A₃'，整合上下文信息，具体公式如下：
    
  4. 稀疏全局注意力（SGA）模块：
  
  通过稀疏全局注意力机制提取长距离特征，提供全局概括能力。SGA模块针对不同阶段的特征X₄采用差异化处理策略。在第1和第2阶段，通过TGFI模块缩小特征尺寸并利用扩张卷积替代全局注意力，生成注意力图并恢复特征尺寸；第3阶段结合视觉注意力机制处理特征；第4阶段直接应用视觉注意力机制。最终，将各阶段输出特征拼接生成最终特征Y。
    
   5. TGFI模块：
     
      通过从输入特征图中提取前k个显著特征并保留其位置信息，建立全局特征交互关系，从而在减轻计算负担的同时扩大感受野，并最终恢复特征图的原始尺寸。




<img width="762" height="590" alt="image" src="https://github.com/user-attachments/assets/b3adfbbc-2129-4f34-9586-24b441097da6" />


四、实验分析

   1. 数据集：涵盖了12个数据集，涉及四个关键遥感视觉任务：场景分类、定向目标检测、语义分割和变化检测。

场景分类实验使用UCM、AID和NWPU数据集；目标检测实验基于DOTA 1.0、DOTA 1.5和DIOR-R数据集；语义分割实验使用UAVid和LoveDA数据集；变化检测实验则涵盖LEVIR-CD、WHU-CD、CDD-CD和SYSU-CD数据集。

   2.评估指标与对比方法：实验通过多种指标评估模型性能，包括场景分类的Top-1准确率、目标检测的mAP、语义分割的mIoU以及变化检测的IoU、F1分数和精度。


<img width="1214" height="743" alt="image" src="https://github.com/user-attachments/assets/f408b881-a2e3-4d0e-a4a9-7f29b761c4f8" />

LWGANet在UCM、AID和NWPU数据集上均表现出色。例如，在NWPU数据集上，LWGANet L0的Top-1准确率达到95.49%，显著高于StarNet S1的94.30%。此外，LWGANet在推理速度上也具有优势，在GPU设备上达到13,234 FPS，而StarNet S1仅为6,045 FPS。


<img width="1272" height="400" alt="image" src="https://github.com/user-attachments/assets/098cb3dd-8456-4178-899e-fb29fe1e721f" />

目标检测任务：在DOTA 1.0测试集上，LWGANet L2实现了78.64%的mAP，超越了现有SOTA模型。DIOR-R测试集上的结果显示，LWGANet L2的mAP为68.53%，比PKINet高出1.5%，同时参数和FLOPs更低。


<img width="1289" height="429" alt="image" src="https://github.com/user-attachments/assets/aaf890b6-7510-4f4b-a300-8335a92b4c72" />

<img width="1242" height="436" alt="image" src="https://github.com/user-attachments/assets/0f39b19d-bb71-4542-9b8f-2b8672cd8626" />


消融实验

<img width="1270" height="325" alt="image" src="https://github.com/user-attachments/assets/6fefe520-b898-44f2-a285-a39de40548c8" />

五、结论 

LWGANet通过引入LWGA模块，有效解决了传统轻量级网络在多尺度特征提取中的不足，显著提升了遥感视觉任务的性能。实验表明，LWGANet在多个数据集上均优于现有SOTA模型，同时保持较低的参数和计算复杂度。

LWGANet为资源受限设备上的遥感图像处理提供了一种新的解决方案，其高效性和准确性使其在实际应用中具有广泛前景。此外，LWGA模块的设计为轻量级网络的发展提供了新思路。

